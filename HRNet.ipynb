{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HRNet \n",
    "Pros: High accuracy, preserves high-resolution details, effective for complex poses. <br>\n",
    "Cons: Requires significant computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach \n",
    "\n",
    "1. Aims to detect 3 keypoints from image I of size W X H X 3 <br>\n",
    "2. State-of-arts method to caldulate heatmaps which help in finding the location confidence of the k_th keypoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the following libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dill in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: numpy in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: torch in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: yacs in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yacs) (6.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\swapn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dill numpy opencv-python torch torchvision matplotlib yacs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os.path\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "from collections import (OrderedDict, namedtuple, defaultdict)\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os.path as osp\n",
    "import sys\n",
    "import argparse\n",
    "import pprint\n",
    "import shutil\n",
    "import warnings\n",
    "from yacs.config import CfgNode as CN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functionalF\n",
    "from torch.autograd import Function\n",
    "from torch.autograd.function import once_differentiable\n",
    "from torch.nn.modules.utils import _pair\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# a convolution function\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, bias=False, dilation=dilation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function used above parameters \n",
    "\n",
    "1. number of input channels \n",
    "2. nunber of output channels \n",
    "3. stride - how much filter moves at each step \n",
    "4. dilation - allows kernel to cover large area of input without changing parameters \n",
    "\n",
    "kernel size is 3x3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Block \n",
    "\n",
    "a convolution block where we applied convulation using block normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1,  downsample=None, dilation=1):\n",
    "        nn.Module.__init__(self)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottle Neck \n",
    "\n",
    "Applying next convulational followed by Batch normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1,  downsample=None, dilation=1):\n",
    "        nn.Module.__init__(self)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=dilation, bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STN\n",
    "\n",
    "this the third convulational block i have applied after Bottle Neck CNN \n",
    "also called as adaptive represenation transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STNBLOCK(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, outplanes, stride=1, downsample=None, dilation=1, deformable_groups=1):\n",
    "        nn.Module.__init__(self)\n",
    "        regular_matrix = torch.tensor(np.array([[-1, -1, -1, 0, 0, 0, 1, 1, 1], \\\n",
    "                                                [-1, 0, 1, -1 ,0 ,1 ,-1, 0, 1]]))\n",
    "        self.register_buffer('regular_matrix', regular_matrix.float())\n",
    "        self.downsample = downsample\n",
    "        self.transform_matrix_conv1 = nn.Conv2d(inplanes, 4, 3, 1, 1, bias=True)\n",
    "        self.stn_conv1 = DeformConv(inplanes,outplanes, kernel_size=3, stride=stride,padding=dilation, dilation=dilation,deformable_groups=deformable_groups)\n",
    "        self.bn1 = nn.BatchNorm2d(outplanes, momentum=BN_MOMENTUM)\n",
    " \n",
    "        self.transform_matrix_conv2 = nn.Conv2d(outplanes, 4, 3, 1, 1, bias=True)            \n",
    "        self.stn_conv2 = DeformConv( outplanes, outplanes, kernel_size=3, stride=1, padding=dilation, dilation=dilation, deformable_groups=deformable_groups)\n",
    "        self.bn2 = nn.BatchNorm2d(outplanes, momentum=BN_MOMENTUM)\n",
    " \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    " \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        (N,C,H,W) = x.shape\n",
    "        transform_matrix1 = self.transform_matrix_conv1(x)\n",
    "        transform_matrix1 = transform_matrix1.permute(0,2,3,1).reshape((N*H*W,2,2))\n",
    "        offset1 = torch.matmul(transform_matrix1, self.regular_matrix)\n",
    "        offset1 = offset1-self.regular_matrix\n",
    "        offset1 = offset1.transpose(1,2)\n",
    "        offset1 = offset1.reshape((N,H,W,18)).permute(0,3,1,2)\n",
    " \n",
    "        out = self.stn_conv1(x, offset1)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        transform_matrix2 = self.transform_matrix_conv2(x)\n",
    "        transform_matrix2 = transform_matrix2.permute(0,2,3,1).reshape((N*H*W,2,2))\n",
    "        offset2 = torch.matmul(transform_matrix2, self.regular_matrix)\n",
    "        offset2 = offset2-self.regular_matrix\n",
    "        offset2 = offset2.transpose(1,2)\n",
    "        offset2 = offset2.reshape((N,H,W,18)).permute(0,3,1,2)\n",
    "        out = self.stn_conv2(out, offset2)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    " \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    " \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Module used by HRNet  model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Basic case  - where the number of branches used is 1 \n",
    "2. Complicated case - where there are more than one branches used hence we fuse these brances\n",
    "\n",
    "Forward method used -- > multiple branches are used and outputs are fused together \n",
    "\n",
    "\n",
    "why ? -- Multiple branches in a network can process features at different scales or resolutions. By fusing the outputs of these branches, the network can integrate features from different scales, which can be beneficial for capturing more comprehensive information about the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    if self.num_branches == 1:\n",
    "        return [self.branches[0](x[0])]\n",
    "\n",
    "    for i in range(self.num_branches):\n",
    "        x[i] = self.branches[i](x[i])\n",
    "\n",
    "    x_fuse = []\n",
    "\n",
    "    for i in range(len(self.fuse_layers)):\n",
    "        y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "        for j in range(1, self.num_branches):\n",
    "            if i == j:\n",
    "                y = y + x[j]\n",
    "            else:\n",
    "                y = y + self.fuse_layers[i][j](x[j])\n",
    "        x_fuse.append(self.relu(y))\n",
    "\n",
    "    return x_fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_one_branch(self, branch_index, block, num_blocks, num_channels, stride=1):\n",
    "    downsample = None\n",
    "    if stride != 1 or  self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "        downsample = nn.Sequential(\n",
    "            nn.Conv2d(self.num_inchannels[branch_index], num_channels[branch_index] * block.expansion, kernel_size=1, stride=stride),\n",
    "            nn.BatchNorm2d(num_channels[branch_index] * block.expansion, momentum=BN_MOMENTUM)\n",
    "        )\n",
    "\n",
    "    layers = []\n",
    "    layers.append(block(self.num_inchannels[branch_index], num_channels[branch_index], stride, downsample))\n",
    "    self.num_inchannels[branch_index] =  num_channels[branch_index] * block.expansion\n",
    "\n",
    "    for i in range(1, num_blocks[branch_index]):\n",
    "        layers.append(block(self.num_inchannels[branch_index], num_channels[branch_index]))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels, num_channels, fuse_method, multi_scale_output=True):\n",
    "        nn.Module.__init__(self)\n",
    "        self._check_branches(num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
    "\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.fuse_method = fuse_method\n",
    "        self.num_branches = num_branches\n",
    "\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "\n",
    "        self.branches = self._make_branches( num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def _check_branches(self, num_branches, blocks, num_blocks,\n",
    "                        num_inchannels, num_channels):\n",
    "        if num_branches != len(num_blocks):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(  num_branches, len(num_blocks))\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_channels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(num_branches, len(num_channels))\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_inchannels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format( num_branches, len(num_inchannels))\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or  self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.num_inchannels[branch_index], num_channels[branch_index] * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_channels[branch_index] * block.expansion, momentum=BN_MOMENTUM)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.num_inchannels[branch_index], num_channels[branch_index], stride, downsample))\n",
    "        self.num_inchannels[branch_index] =  num_channels[branch_index] * block.expansion\n",
    "        \n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(block(self.num_inchannels[branch_index], num_channels[branch_index]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branches.append(self._make_one_branch(i, block, num_blocks, num_channels))\n",
    "\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "\n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    fuse_layer.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_inchannels[j], num_inchannels[i],1,1,0, bias=False),\n",
    "                        nn.BatchNorm2d(num_inchannels[i]),\n",
    "                        nn.Upsample(scale_factor=2**(j-i), mode='nearest')))\n",
    "                elif j == i:\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    conv3x3s = []\n",
    "                    for k in range(i-j):\n",
    "                        if k == i - j - 1:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],num_outchannels_conv3x3, 3, 2, 1, bias=False),\n",
    "                                nn.BatchNorm2d(num_outchannels_conv3x3)))\n",
    "                        else:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j], num_outchannels_conv3x3, 3, 2, 1, bias=False),\n",
    "                                nn.BatchNorm2d(num_outchannels_conv3x3),\n",
    "                                nn.ReLU(True)))\n",
    "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "\n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_num_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_branches == 1:\n",
    "            return [self.branches[0](x[0])]\n",
    "\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "\n",
    "        x_fuse = []\n",
    "\n",
    "        for i in range(len(self.fuse_layers)):\n",
    "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "            for j in range(1, self.num_branches):\n",
    "                if i == j:\n",
    "                    y = y + x[j]\n",
    "                else:\n",
    "                    y = y + self.fuse_layers[i][j](x[j])\n",
    "            x_fuse.append(self.relu(y))\n",
    "\n",
    "        return x_fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common params for NETWORK\n",
    "cfgMODEL = CN()\n",
    "cfgMODEL.NAME = 'pose_hrnet'\n",
    "cfgMODEL.INIT_WEIGHTS = True\n",
    "cfgMODEL.PRETRAINED = '' # 'model/imagenet/hrnet_w32-36af842e.pth'\n",
    "cfgMODEL.NUM_JOINTS = 15 # 14\n",
    "cfgMODEL.EXTRA = CN(new_allowed=True)\n",
    "\n",
    "cfgMODEL.EXTRA.FINAL_CONV_KERNEL = 1\n",
    "cfgMODEL.EXTRA.PRETRAINED_LAYERS = ['*']\n",
    "cfgMODEL.EXTRA.STEM_INPLANES =  64\n",
    "\n",
    "cfgMODEL.EXTRA.STAGE2 = CN(new_allowed=True)\n",
    "cfgMODEL.EXTRA.STAGE2.NUM_MODULES = 1\n",
    "cfgMODEL.EXTRA.STAGE2.NUM_BRANCHES = 2\n",
    "cfgMODEL.EXTRA.STAGE2.BLOCK = 'BASIC'\n",
    "cfgMODEL.EXTRA.STAGE2.NUM_BLOCKS = [4, 4]\n",
    "cfgMODEL.EXTRA.STAGE2.NUM_CHANNELS = [32, 64]\n",
    "cfgMODEL.EXTRA.STAGE2.FUSE_METHOD = 'SUM'\n",
    "\n",
    "cfgMODEL.EXTRA.STAGE3 = CN(new_allowed=True)\n",
    "cfgMODEL.EXTRA.STAGE3.NUM_MODULES = 4\n",
    "cfgMODEL.EXTRA.STAGE3.NUM_BRANCHES = 3\n",
    "cfgMODEL.EXTRA.STAGE3.BLOCK = 'BASIC'\n",
    "cfgMODEL.EXTRA.STAGE3.NUM_BLOCKS = [4, 4, 4]\n",
    "cfgMODEL.EXTRA.STAGE3.NUM_CHANNELS = [32, 64, 128]\n",
    "cfgMODEL.EXTRA.STAGE3.FUSE_METHOD = 'SUM'\n",
    "\n",
    "cfgMODEL.EXTRA.STAGE4 = CN(new_allowed=True)\n",
    "cfgMODEL.EXTRA.STAGE4.NUM_MODULES = 3\n",
    "cfgMODEL.EXTRA.STAGE4.NUM_BRANCHES = 4\n",
    "cfgMODEL.EXTRA.STAGE4.BLOCK = 'BASIC'\n",
    "cfgMODEL.EXTRA.STAGE4.NUM_BLOCKS = [4, 4, 4, 4]\n",
    "cfgMODEL.EXTRA.STAGE4.NUM_CHANNELS = [32, 64, 128, 256]\n",
    "cfgMODEL.EXTRA.STAGE4.FUSE_METHOD = 'SUM'\n",
    "\n",
    "cfgMODEL.EXTRA.DECONV = CN(new_allowed=True)\n",
    "cfgMODEL.EXTRA.DECONV.NUM_DECONVS = 0\n",
    "cfgMODEL.EXTRA.DECONV.NUM_CHANNELS = [32]\n",
    "cfgMODEL.EXTRA.DECONV.KERNEL_SIZE = 4\n",
    "cfgMODEL.EXTRA.DECONV.NUM_BASIC_BLOCKS = 0\n",
    "cfgMODEL.EXTRA.DECONV.CAT_OUTPUT = True\n",
    "\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_HEATMAP = CN(new_allowed=True)\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_HEATMAP.BLOCK = ['STNBLOCK','STNBLOCK','STNBLOCK']\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_HEATMAP.NUM_BLOCKS = [1,1,1]\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_HEATMAP.NUM_CHANNELS = [32,32,32]\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_HEATMAP.DILATION_RATE = [1,2,3]\n",
    "\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_REGRESSION = CN(new_allowed=True)\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_REGRESSION.BLOCK = ['STNBLOCK']\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_REGRESSION.NUM_BLOCKS = [1]\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_REGRESSION.NUM_CHANNELS = [256]\n",
    "cfgMODEL.EXTRA.MULTI_LEVEL_OUTPUT_REGRESSION.DILATION_RATE = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.layer1(x)\n",
    "\n",
    "    x_list = []\n",
    "    for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "        if self.transition1[i] is not None:\n",
    "            x_list.append(self.transition1[i](x))\n",
    "        else:\n",
    "            x_list.append(x)\n",
    "    y_list = self.stage2(x_list)\n",
    "\n",
    "    x_list = []\n",
    "    for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "        if self.transition2[i] is not None:\n",
    "            x_list.append(self.transition2[i](y_list[-1]))\n",
    "        else:\n",
    "            x_list.append(y_list[i])\n",
    "    y_list = self.stage3(x_list)\n",
    "\n",
    "    x_list = []\n",
    "    for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "        if self.transition3[i] is not None:\n",
    "            x_list.append(self.transition3[i](y_list[-1]))\n",
    "        else:\n",
    "            x_list.append(y_list[i])\n",
    "    x = self.stage4(x_list)\n",
    "\n",
    "    # Upsampling\n",
    "    x0_h, x0_w = x[0].size(2), x[0].size(3)\n",
    "\n",
    "    x = torch.cat([x[0], \\\n",
    "        functionalF.upsample(x[1],size=(x0_h, x0_w), mode='bilinear'), \\\n",
    "        functionalF.upsample(x[2], size=(x0_h, x0_w), mode='bilinear'), \\\n",
    "        functionalF.upsample(x[3], size=(x0_h, x0_w), mode='bilinear')], 1)\n",
    "\n",
    "    final_outputs = []\n",
    "    final_offsets = []\n",
    "\n",
    "    final_output = []\n",
    "    final_offset = []\n",
    "\n",
    "    for j in range(len(self.multi_level_layers_4x_heatmap)):\n",
    "        final_output.append(self.final_layers[0](self.multi_level_layers_4x_heatmap[j](self.transition_cls(x))))\n",
    "\n",
    "    x = torch.cat([x, torch.mean(torch.stack(final_output), 0)], 1)\n",
    "\n",
    "    for j in range(len(self.multi_level_layers_4x_regression)):\n",
    "        final_offset.append(self.final_layers[1](self.multi_level_layers_4x_regression[j](self.transition_reg(x))))\n",
    "\n",
    "    for i in range(len(final_output)):\n",
    "        final_output[i] = torch.cat([final_output[i], final_offset[0][:,-1:,:,:]], 1)\n",
    "\n",
    "    final_outputs.append([torch.mean(torch.stack(final_output), 0)])\n",
    "    final_offsets.append([final_offset[0][:,:-1,:,:]])\n",
    "\n",
    "    return final_outputs, final_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseHigherResolutionNet(nn.Module):\n",
    "    def __init__(self, cfgMODEL, cfgDATASET,cfgLOSS, **kwargs):\n",
    "        self.inplanes = 64\n",
    "        self.dim_heat = cfgDATASET.NUM_JOINTS-1 if cfgDATASET.WITH_CENTER else cfgDATASET.NUM_JOINTS\n",
    "        self.dim_reg = self.dim_heat * 2 + 1\n",
    "        extra = cfgMODEL.EXTRA\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        # stem net\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,  bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(Bottleneck, 64, 64, 4)\n",
    "\n",
    "        self.stage2_cfg = cfgMODEL['EXTRA']['STAGE2']\n",
    "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
    "        num_channels = [ num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition1 = self._make_transition_layer([256], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage( self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = cfgMODEL['EXTRA']['STAGE3']\n",
    "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
    "        num_channels = [ num_channels[i] * block.expansion for i in range(len(num_channels)) ]\n",
    "        self.transition2 = self._make_transition_layer( pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage( self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = cfgMODEL['EXTRA']['STAGE4']\n",
    "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
    "        num_channels = [ num_channels[i] * block.expansion for i in range(len(num_channels)) ]\n",
    "        self.transition3 = self._make_transition_layer( pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage( self.stage4_cfg, num_channels, multi_scale_output=True)\n",
    "        \n",
    "        inp_channels = np.int(np.sum(pre_stage_channels))\n",
    "        multi_output_config_heatmap = cfgMODEL['EXTRA']['MULTI_LEVEL_OUTPUT_HEATMAP']\n",
    "        multi_output_config_regression = cfgMODEL['EXTRA']['MULTI_LEVEL_OUTPUT_REGRESSION']\n",
    "        self.transition_cls = nn.Sequential(\n",
    "                                nn.Conv2d(inp_channels,multi_output_config_heatmap['NUM_CHANNELS'][0], 1, 1, 0, bias=False),\n",
    "                                nn.BatchNorm2d(multi_output_config_heatmap['NUM_CHANNELS'][0]),\n",
    "                                nn.ReLU(True))\n",
    "        self.transition_reg = nn.Sequential(\n",
    "                                nn.Conv2d(inp_channels + self.dim_heat, multi_output_config_regression['NUM_CHANNELS'][0],  1, 1, 0, bias=False),\n",
    "                                nn.BatchNorm2d(multi_output_config_regression['NUM_CHANNELS'][0]),\n",
    "                                nn.ReLU(True))\n",
    "        self.multi_level_layers_4x_heatmap = self._make_multi_level_layer( multi_output_config_heatmap)\n",
    "        self.multi_level_layers_4x_regression = self._make_multi_level_layer( multi_output_config_regression)\n",
    "        \n",
    "        self.final_layers = self._make_final_layers(  cfgMODEL,cfgDATASET, multi_output_config_heatmap, multi_output_config_regression)\n",
    "        #self.deconv_layers = self._make_deconv_layers( cfgMODEL, pre_stage_channels[0])\n",
    "\n",
    "        self.num_deconvs = extra.DECONV.NUM_DECONVS\n",
    "        self.deconv_config = cfgMODEL.EXTRA.DECONV\n",
    "        self.loss_config = cfgLOSS\n",
    "\n",
    "        self.pretrained_layers = cfgMODEL['EXTRA']['PRETRAINED_LAYERS']\n",
    "\n",
    "    def _make_final_layers(self, cfgMODEL,cfgDATASET, multi_output_config_heatmap, multi_output_config_regression):\n",
    "        extra = cfgMODEL.EXTRA\n",
    "\n",
    "        final_layers = []\n",
    "        final_layers.append(nn.Conv2d(in_channels=multi_output_config_heatmap['NUM_CHANNELS'][0],out_channels=self.dim_heat,\n",
    "            kernel_size=extra.FINAL_CONV_KERNEL,stride=1,padding=1 if extra.FINAL_CONV_KERNEL == 3 else 0 ))\n",
    "\n",
    "        # for regression\n",
    "        if cfgDATASET.OFFSET_REG:\n",
    "            final_layers.append(nn.Conv2d(\n",
    "                in_channels=multi_output_config_regression['NUM_CHANNELS'][0], out_channels=self.dim_reg,\n",
    "                kernel_size=extra.FINAL_CONV_KERNEL, stride=1, padding=1 if extra.FINAL_CONV_KERNEL == 3 else 0))\n",
    "\n",
    "        return nn.ModuleList(final_layers)\n",
    "\n",
    "    def _make_layer( self, block, inplanes, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample, dilation=dilation))\n",
    "        inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_multi_level_layer(self, layer_config):\n",
    "        multi_level_layers = []\n",
    "\n",
    "        first_branch = self._make_layer(\n",
    "                blocks_dict[layer_config['BLOCK'][0]],\n",
    "                layer_config['NUM_CHANNELS'][0],\n",
    "                layer_config['NUM_CHANNELS'][0],\n",
    "                layer_config['NUM_BLOCKS'][0],\n",
    "                dilation=layer_config['DILATION_RATE'][0]\n",
    "        )\n",
    "        multi_level_layers.append(first_branch)\n",
    "        \n",
    "        for i, d in enumerate(layer_config['DILATION_RATE'][1:]):\n",
    "            branch = self._make_layer(\n",
    "                blocks_dict[layer_config['BLOCK'][i+1]],\n",
    "                layer_config['NUM_CHANNELS'][i+1],\n",
    "                layer_config['NUM_CHANNELS'][i+1],\n",
    "                layer_config['NUM_BLOCKS'][i+1],\n",
    "                dilation=d\n",
    "            )\n",
    "\n",
    "            for module in zip(first_branch.named_modules(), branch.named_modules()):\n",
    "                if 'conv' in module[0][0] and 'conv' in module[1][0]:\n",
    "                    module[1][1].weight = module[0][1].weight\n",
    "\n",
    "            multi_level_layers.append(branch)\n",
    "\n",
    "        return nn.ModuleList(multi_level_layers)\n",
    "\n",
    "    def _make_deconv_layers(self, cfgMODEL, input_channels):\n",
    "        dim_tag = cfgMODEL.NUM_JOINTS\n",
    "        extra = cfgMODEL.EXTRA\n",
    "        deconv_cfg = extra.DECONV\n",
    "\n",
    "        deconv_layers = []\n",
    "        for i in range(deconv_cfg.NUM_DECONVS):\n",
    "            if deconv_cfg.CAT_OUTPUT[i]:\n",
    "                final_output_channels = cfgMODEL.NUM_JOINTS + dim_tag  if cfgLOSS.WITH_AE_LOSS[i] else cfgMODEL.NUM_JOINTS\n",
    "                input_channels += final_output_channels\n",
    "            output_channels = deconv_cfg.NUM_CHANNELS[i]\n",
    "            deconv_kernel, padding, output_padding =  self._get_deconv_cfg(deconv_cfg.KERNEL_SIZE[i])\n",
    "\n",
    "            layers = []\n",
    "            layers.append(nn.Sequential(\n",
    "                nn.ConvTranspose2d( in_channels=input_channels,out_channels=output_channels,\n",
    "                    kernel_size=deconv_kernel,stride=2, padding=padding,output_padding=output_padding, bias=False),\n",
    "                nn.BatchNorm2d(output_channels, momentum=BN_MOMENTUM),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "            for _ in range(cfgMODEL.EXTRA.DECONV.NUM_BASIC_BLOCKS):\n",
    "                layers.append(nn.Sequential( BasicBlock(output_channels, output_channels)))\n",
    "            deconv_layers.append(nn.Sequential(*layers))\n",
    "            input_channels = output_channels\n",
    "\n",
    "        return nn.ModuleList(deconv_layers)\n",
    "\n",
    "    def _get_deconv_cfg(self, deconv_kernel):\n",
    "        if deconv_kernel == 4:\n",
    "            padding = 1\n",
    "            output_padding = 0\n",
    "        elif deconv_kernel == 3:\n",
    "            padding = 1\n",
    "            output_padding = 1\n",
    "        elif deconv_kernel == 2:\n",
    "            padding = 0\n",
    "            output_padding = 0\n",
    "\n",
    "        return deconv_kernel, padding, output_padding\n",
    "\n",
    "    def _make_transition_layer(self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_channels_pre_layer[i], num_channels_cur_layer[i], 3, 1, 1, bias=False),\n",
    "                        nn.BatchNorm2d(num_channels_cur_layer[i]),\n",
    "                        nn.ReLU(inplace=True)))\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i+1-num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] if j == i-num_branches_pre else inchannels\n",
    "                    conv3x3s.append(nn.Sequential(\n",
    "                        nn.Conv2d(inchannels, outchannels, 3, 2, 1, bias=False),\n",
    "                        nn.BatchNorm2d(outchannels),\n",
    "                        nn.ReLU(inplace=True)))\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = blocks_dict[layer_config['BLOCK']]\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "\n",
    "            modules.append(HighResolutionModule(num_branches,block,num_blocks,num_inchannels,num_channels,fuse_method, reset_multi_scale_output) )\n",
    "            num_inchannels = modules[-1].get_num_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list = self.stage2(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "            if self.transition2[i] is not None:\n",
    "                x_list.append(self.transition2[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage3(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "            if self.transition3[i] is not None:\n",
    "                x_list.append(self.transition3[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        x = self.stage4(x_list)\n",
    "\n",
    "        # Upsampling\n",
    "        x0_h, x0_w = x[0].size(2), x[0].size(3)\n",
    "\n",
    "        x = torch.cat([x[0], \\\n",
    "            functionalF.upsample(x[1],size=(x0_h, x0_w), mode='bilinear'), \\\n",
    "            functionalF.upsample(x[2], size=(x0_h, x0_w), mode='bilinear'), \\\n",
    "            functionalF.upsample(x[3], size=(x0_h, x0_w), mode='bilinear')], 1)\n",
    "\n",
    "        final_outputs = []\n",
    "        final_offsets = []\n",
    "\n",
    "        final_output = []\n",
    "        final_offset = []\n",
    "\n",
    "        for j in range(len(self.multi_level_layers_4x_heatmap)):\n",
    "            final_output.append(self.final_layers[0](self.multi_level_layers_4x_heatmap[j](self.transition_cls(x))))\n",
    "\n",
    "        x = torch.cat([x, torch.mean(torch.stack(final_output), 0)], 1)\n",
    "    \n",
    "        for j in range(len(self.multi_level_layers_4x_regression)):\n",
    "            final_offset.append(self.final_layers[1](self.multi_level_layers_4x_regression[j](self.transition_reg(x))))\n",
    "\n",
    "        for i in range(len(final_output)):\n",
    "            final_output[i] = torch.cat([final_output[i], final_offset[0][:,-1:,:,:]], 1)\n",
    "        \n",
    "        final_outputs.append([torch.mean(torch.stack(final_output), 0)])\n",
    "        final_offsets.append([final_offset[0][:,:-1,:,:]])\n",
    "\n",
    "        return final_outputs, final_offsets\n",
    "\n",
    "    def init_weights(self, pretrained='', verbose=True):\n",
    "        print('=> init weights from normal distribution')\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "                for name, _ in m.named_parameters():\n",
    "                    if name in ['bias']:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "                for name, _ in m.named_parameters():\n",
    "                    if name in ['bias']:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if hasattr(m, 'conv_mask_offset_1'):\n",
    "                nn.init.constant_(m.conv_mask_offset_1.weight, 0)\n",
    "                nn.init.constant_(m.conv_mask_offset_1.bias, 0)\n",
    "            if hasattr(m, 'conv_mask_offset_2'):\n",
    "                nn.init.constant_(m.conv_mask_offset_2.weight, 0)\n",
    "                nn.init.constant_(m.conv_mask_offset_2.bias, 0)\n",
    "            if hasattr(m, 'transform_matrix_conv1'):\n",
    "                nn.init.constant_(m.transform_matrix_conv1.weight, 0)\n",
    "                nn.init.constant_(m.transform_matrix_conv1.bias, 0)\n",
    "            if hasattr(m, 'transform_matrix_conv2'):\n",
    "                nn.init.constant_(m.transform_matrix_conv2.weight, 0)\n",
    "                nn.init.constant_(m.transform_matrix_conv2.bias, 0)\n",
    "\n",
    "        parameters_names = set()\n",
    "        for name, _ in self.named_parameters():\n",
    "            parameters_names.add(name)\n",
    "\n",
    "        buffers_names = set()\n",
    "        for name, _ in self.named_buffers():\n",
    "            buffers_names.add(name)\n",
    "\n",
    "        if os.path.isfile(pretrained):\n",
    "            pretrained_state_dict = torch.load(pretrained, \n",
    "                            map_location=lambda storage, loc: storage)\n",
    "            print('=> loading pretrained model {}'.format(pretrained))\n",
    "\n",
    "            need_init_state_dict = {}\n",
    "            for name, m in pretrained_state_dict.items():\n",
    "                if name.split('.')[0] in self.pretrained_layers \\\n",
    "                   or self.pretrained_layers[0] is '*':\n",
    "                    if name in parameters_names or name in buffers_names:\n",
    "                        if verbose:\n",
    "                            print('=> init {} from {}'.format(name, pretrained))\n",
    "                        need_init_state_dict[name] = m\n",
    "            self.load_state_dict(need_init_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HighResolutionModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m dill\u001b[38;5;241m.\u001b[39mdump(Bottleneck, f, byref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m dill\u001b[38;5;241m.\u001b[39mdump(STNBLOCK, f, byref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m dill\u001b[38;5;241m.\u001b[39mdump(\u001b[43mHighResolutionModule\u001b[49m, f, byref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m dill\u001b[38;5;241m.\u001b[39mdump(PoseHigherResolutionNet, f, byref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HighResolutionModule' is not defined"
     ]
    }
   ],
   "source": [
    "with open('model_funcs.pkl', 'wb') as f:\n",
    "    dill.dump(cfgMODEL, f)\n",
    "    dill.dump(conv3x3, f)\n",
    "    dill.dump(BasicBlock, f, byref=False)\n",
    "    dill.dump(Bottleneck, f, byref=False)\n",
    "    dill.dump(STNBLOCK, f, byref=False)\n",
    "    dill.dump(HighResolutionModule, f, byref=False)\n",
    "    dill.dump(PoseHigherResolutionNet, f, byref=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
